{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "import fasttext\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Facebook FastText Pre-trained Model\n",
    "pre_train_model = fasttext.load_model('wiki.en.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Definitions\n",
    "#### Preprocesing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    # Read in CSV File into DataFrame\n",
    "    list_var = []\n",
    "    data = pd.DataFrame()\n",
    "    with open(filename,'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for i in reader:\n",
    "            list_var.append(i)\n",
    "    # Header & Data\n",
    "    col_name = list_var[0]\n",
    "    data_val = list_var[1:]\n",
    "    # Convert to DataFrame\n",
    "    data = pd.DataFrame(data_val, columns=col_name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data,clean):\n",
    "    # Clean and Tokenize both Name and Description Field\n",
    "    temp_name = data['name'].copy()\n",
    "    temp_description = data['description'].copy()\n",
    "    df = data.copy()\n",
    "    # Raw\n",
    "    if clean=='Raw':\n",
    "        pass\n",
    "    # Semi-Cleaned \n",
    "    elif clean=='Nspace':\n",
    "        # Remove Symbols in Name and Description Column (no space)\n",
    "        temp_name = [re.sub(r'[^\\w\\s]','',x) for x in temp_name]\n",
    "        temp_description = [re.sub(r'[^\\w\\s]','',x) for x in temp_description]\n",
    "    elif clean=='Wspace':\n",
    "        # Remove Symbols in Name and Description Column (replace with space)\n",
    "        temp_name = [re.sub(r'[^\\w\\s]',' ',x) for x in temp_name]\n",
    "        temp_description = [re.sub(r'[^\\w\\s]',' ',x) for x in temp_description]\n",
    "    # Tokenize: Split single sentence into list of words\n",
    "    for i in range(0,len(temp_name),1):\n",
    "        # Tokenize Name and Description Columns into words\n",
    "        df['name'][i] = word_tokenize(temp_name[i])\n",
    "        df['description'][i] = word_tokenize(temp_description[i])\n",
    "        try:\n",
    "            df['name'][i].remove('')\n",
    "        except ValueError:\n",
    "            pass  # do nothing!\n",
    "        try:\n",
    "            df['description'][i].remove('')\n",
    "        except ValueError:\n",
    "            pass  # do nothing!\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df,model):\n",
    "    # Vectorize the list of words and then average the vectors into one sentence vector\n",
    "    df_vectorize = df.copy()\n",
    "    counter = 0\n",
    "    for i in df['name']:\n",
    "        array = [model.get_word_vector(x) for x in i]\n",
    "        avg = np.average(array, axis=0)\n",
    "        df_vectorize['name'][counter] = avg\n",
    "        counter += 1\n",
    "    df_concat = pd.concat([df.id,df_vectorize.name],axis=1)\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_vector(file,clean,model):\n",
    "    # Read in Abt File\n",
    "    df = read_file(file)\n",
    "    if 'title' in df.columns:\n",
    "        df['name']=df['title'].copy()\n",
    "    # Clean & Tokenize\n",
    "    temp = tokenize(df,clean)\n",
    "    df.name = temp.name\n",
    "    # Vectorize name column\n",
    "    data = vectorize(df,model)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(df,df2,clean):\n",
    "    # Change Column names to 'name' instead of 'title'\n",
    "    if 'title' in df.columns:\n",
    "        df['name']=df['title'].copy()\n",
    "    if 'title' in df2.columns:\n",
    "        df2['name']=df2['title'].copy()  \n",
    "    # Combine name and description text\n",
    "    df['combine'] = df['name'] + ' ' + df['description']\n",
    "    df2['combine'] = df2['name'] + ' ' + df2['description']\n",
    "    # Create Corpus to train TFIDF\n",
    "    # With option for Raw vs Cleaned\n",
    "    corpus = []\n",
    "    for i in range(0,len(df['combine']),1):\n",
    "        temp = df['combine'][i]\n",
    "        if clean=='Raw':\n",
    "            pass\n",
    "        elif clean=='Nspace':\n",
    "            temp = re.sub(r'[^\\w\\s]','',temp)\n",
    "        elif clean=='Wspace':\n",
    "            temp = re.sub(r'[^\\w\\s]',' ',temp)\n",
    "        corpus.append(temp)\n",
    "    for i in range(0,len(df2['combine']),1):\n",
    "        temp = df2['combine'][i]\n",
    "        if clean=='Raw':\n",
    "            pass\n",
    "        elif clean=='Nspace':\n",
    "            temp = re.sub(r'[^\\w\\s]','',temp)\n",
    "        elif clean=='Wspace':\n",
    "            temp = re.sub(r'[^\\w\\s]',' ',temp)\n",
    "        corpus.append(temp)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_vect(file1,file2,clean):\n",
    "    # Read in Files\n",
    "    df = read_file(file1)\n",
    "    df2 = read_file(file2)\n",
    "    corpus = create_corpus(df,df2,clean)\n",
    "    # Fit TF-IDF Model\n",
    "    vectorizer = TfidfVectorizer(max_features=300)\n",
    "    tfidf_model = vectorizer.fit(corpus)\n",
    "    # Generate TF-IDF Vectors for each product\n",
    "    arr = []\n",
    "    for i in range(0,len(df),1):\n",
    "        text = df['name'][i]\n",
    "        arr.append(tfidf_model.transform([text]).toarray()[0])\n",
    "    df['name'] = arr\n",
    "    arr = []\n",
    "    for i in range(0,len(df2),1):\n",
    "        text = df2['name'][i]\n",
    "        arr.append(tfidf_model.transform([text]).toarray()[0])\n",
    "    df2['name'] = arr\n",
    "    \n",
    "    return df[['id','name']], df2[['id','name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Ranked List Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_length(a):\n",
    "    return float(math.sqrt(sum(x*x for x in a)))\n",
    "def dot_product(a,b):\n",
    "    if len(a) == len(b):\n",
    "        return sum([x*y for (x,y) in zip(a,b)])\n",
    "    else:\n",
    "        return \"Vector Length Different\"\n",
    "def cos_similarity(a,b):\n",
    "    return dot_product(a,b)/(vector_length(a)*vector_length(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_ranking(df1,df2):\n",
    "    # Initialize Ranking Chart\n",
    "    col_names = ['df1_id','1','2','3','4','5','6','7','8','9','10']\n",
    "    df_ranking = pd.DataFrame(columns=col_names);\n",
    "    # Loop for every Abt_id element\n",
    "    for i in range(0,len(df1.name),1):\n",
    "        cos_sim = []\n",
    "        # Loop for computing buy_id ranking for current Abt_id\n",
    "        for j in range(0,len(df2.name),1):\n",
    "            # Compute Cosine Similarity for every buy_id element compared to current Abt_id\n",
    "            cos_sim.append(cos_similarity(df1.name[i],df2.name[j]))\n",
    "        # Sort list and pick top 10\n",
    "        temp_df = pd.DataFrame(cos_sim)\n",
    "        temp_sorted = temp_df.sort_values(by=0,ascending=False)\n",
    "        row_ranking = temp_sorted.index.values[0:10]\n",
    "        rank_buy_id = []\n",
    "        # Convert row # into buy_id\n",
    "        for k in row_ranking:\n",
    "            rank_buy_id.append(df2.id.iloc[k])\n",
    "        rank_buy_id.insert(0,df1.id[i])\n",
    "        # Concat into Abt Ranking Chart\n",
    "        combine_df = pd.DataFrame([rank_buy_id],columns=col_names)\n",
    "        df_ranking = pd.concat([df_ranking,combine_df],names=col_names,sort=False,ignore_index=True)\n",
    "    return df_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgcos_top_10_ranking(df1,df2,df3,df4):\n",
    "    # df1 & df2 from First Model\n",
    "    # df3 & df4 from Second Model\n",
    "    # Initialize Ranking Chart\n",
    "    col_names = ['df1_id','1','2','3','4','5','6','7','8','9','10']\n",
    "    df_ranking = pd.DataFrame(columns=col_names);\n",
    "    # Loop for every Abt_id element\n",
    "    for i in range(0,len(df1.name),1):\n",
    "        cos_sim = []\n",
    "        # Loop for computing buy_id ranking for current Abt_id\n",
    "        for j in range(0,len(df2.name),1):\n",
    "            # Compute Cosine Similarity for 2 models and average their cos sim\n",
    "            score1 = cos_similarity(df1.name[i],df2.name[j])\n",
    "            score2 = cos_similarity(df3.name[i],df4.name[j])\n",
    "            meanscore = (score1+score2)/2\n",
    "            cos_sim.append(meanscore)\n",
    "        # Sort list and pick top 10\n",
    "        temp_df = pd.DataFrame(cos_sim) \n",
    "        temp_sorted = temp_df.sort_values(by=0,ascending=False)\n",
    "        row_ranking = temp_sorted.index.values[0:10]\n",
    "        rank_buy_id = []\n",
    "        # Convert row # into buy_id\n",
    "        for k in row_ranking:\n",
    "            rank_buy_id.append(df2.id.iloc[k])\n",
    "        rank_buy_id.insert(0,df1.id[i])\n",
    "        # Concat into Abt Ranking Chart\n",
    "        combine_df = pd.DataFrame([rank_buy_id],columns=col_names)\n",
    "        df_ranking = pd.concat([df_ranking,combine_df],names=col_names,sort=False,ignore_index=True)\n",
    "    return df_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_ranking_loc(df_ranking,mapping,col1,col2):\n",
    "    # Find where ground truth is ranked \n",
    "    col_names = ['df1_id','Ranked_Location']\n",
    "    df_rank_loc = pd.DataFrame(columns=col_names)\n",
    "    # Loop for every element of Abt_id from df_ranking\n",
    "    for i in range(0,len(df_ranking.df1_id),1):\n",
    "        # Look for ground truth from True Mapping\n",
    "        look_up_id = df_ranking.df1_id[i]\n",
    "        # Check if product is in Perfect Mapping\n",
    "        if len(mapping[col2][mapping[col1]==look_up_id])!=0:\n",
    "            mapped_id = mapping[col2][mapping[col1]==look_up_id].values[0]\n",
    "            # Check if ground truth in ranking list and note its location\n",
    "            if mapped_id in list(df_ranking.iloc[i]):\n",
    "                ranking = list(df_ranking.iloc[i]).index(mapped_id)\n",
    "            else:\n",
    "                ranking = 0\n",
    "            # Concat into Abt Ranking Location df\n",
    "            temp_list = list([look_up_id,ranking])\n",
    "            temp_df2 = pd.DataFrame([temp_list],columns=col_names)\n",
    "            df_rank_loc = pd.concat([df_rank_loc,temp_df2],names=col_names,sort=False,ignore_index=True)\n",
    "    return df_rank_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_at_n(df_rank_loc,n):\n",
    "    # Sum the correct ranks at ranks 1 to n divide by n number of ranks\n",
    "    HR_n_sum = 0\n",
    "    for i in range(0,len(df_rank_loc),1):\n",
    "        if df_rank_loc.Ranked_Location[i]!=0:\n",
    "            if df_rank_loc.Ranked_Location[i]<=n:\n",
    "                HR_n_sum += 1\n",
    "    Hits_Rate_at_n = HR_n_sum/len(df_rank_loc)\n",
    "    return Hits_Rate_at_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(df_rank_loc):\n",
    "    # Sum the Reciprocal Rank of Abt Ranking Location df and divide by total number element\n",
    "    MRR_sum = 0\n",
    "    for i in range(0,len(df_rank_loc),1):\n",
    "        if df_rank_loc.Ranked_Location[i]!=0:\n",
    "            MRR_sum += 1/df_rank_loc.Ranked_Location[i]\n",
    "    mean_reciprocal_rank = MRR_sum/len(df_rank_loc)\n",
    "    return mean_reciprocal_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://gist.github.com/bwhite/3726239\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not idcg:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / idcg\n",
    "\n",
    "def ndcg(df_rank_loc,k):\n",
    "    # Sum up all NDCG at each Queries and divided by total # of Queries\n",
    "    # Initalize Ranking Encoding\n",
    "    rank_encoding = {0:[0,0,0,0,0,0,0,0,0,0],\n",
    "                     1:[1,0,0,0,0,0,0,0,0,0],\n",
    "                     2:[0,1,0,0,0,0,0,0,0,0],\n",
    "                     3:[0,0,1,0,0,0,0,0,0,0],\n",
    "                     4:[0,0,0,1,0,0,0,0,0,0],\n",
    "                     5:[0,0,0,0,1,0,0,0,0,0],\n",
    "                     6:[0,0,0,0,0,1,0,0,0,0],\n",
    "                     7:[0,0,0,0,0,0,1,0,0,0],\n",
    "                     8:[0,0,0,0,0,0,0,1,0,0],\n",
    "                     9:[0,0,0,0,0,0,0,0,1,0],\n",
    "                     10:[0,0,0,0,0,0,0,0,0,1]}\n",
    "    sum_NDCG = 0\n",
    "    for i in df_rank_loc.Ranked_Location:\n",
    "        sum_NDCG += ndcg_at_k(rank_encoding[i], k)\n",
    "    NDCG = sum_NDCG/len(df_rank_loc)\n",
    "    return NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All in One Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_one(file1,file2,mapping,clean,unsupervised_model,pre_train_model):\n",
    "    # Generate Unsupervised Model\n",
    "    # Read File 1 & Vectorize\n",
    "    data1_1 = file_to_vector(file1,clean,unsupervised_model)\n",
    "    # Read File 2 & Vectorize\n",
    "    data2_1 = file_to_vector(file2,clean,unsupervised_model)\n",
    "    # FastText Pre-Trained\n",
    "    # Read File 1 & Vectorize\n",
    "    data1_2 = file_to_vector(file1,clean,pre_train_model)\n",
    "    # Read File 2 & Vectorize\n",
    "    data2_2 = file_to_vector(file2,clean,pre_train_model)\n",
    "    # Read Perfect Mapping\n",
    "    mapping = read_file(mapping)\n",
    "    # Create Ranking List\n",
    "    df_ranking = avgcos_top_10_ranking(data1_1,data2_1,data1_2,data2_2)\n",
    "    # Find Location where True Ranking Occured \n",
    "    df_rank_loc = true_ranking_loc(df_ranking,mapping,mapping.columns[0],mapping.columns[1])\n",
    "    return df_rank_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abt vs Buy (Raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      "Hit Rate at 10:  0.8038852913968547\n",
      "Mean Reciprocal Rank:  0.6065088909445981\n",
      "NDCG at 10 Score:  0.6539332996420198\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "unsupervised_model = fasttext.train_unsupervised('abt_buy_raw.txt', model='skipgram',dim=300)\n",
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Raw',unsupervised_model,pre_train_model)\n",
    "print(\"Raw\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abt vs Buy (Cleaned No Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nspace\n",
      "Hit Rate at 10:  0.8362627197039778\n",
      "Mean Reciprocal Rank:  0.6412584614481006\n",
      "NDCG at 10 Score:  0.6878854403915262\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "unsupervised_model = fasttext.train_unsupervised('abt_buy_nspace.txt', model='skipgram',dim=300)\n",
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Nspace',unsupervised_model,pre_train_model)\n",
    "print(\"Nspace\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abt vs Buy (Cleaned With Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wspace\n",
      "Hit Rate at 10:  0.7382053654024052\n",
      "Mean Reciprocal Rank:  0.5325760245510476\n",
      "NDCG at 10 Score:  0.5814450546965393\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "unsupervised_model = fasttext.train_unsupervised('abt_buy_wspace.txt', model='skipgram',dim=300)\n",
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Wspace',unsupervised_model,pre_train_model)\n",
    "print(\"Wspace\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon vs Google (Raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      "Hit Rate at 10:  0.5920444033302498\n",
      "Mean Reciprocal Rank:  0.45659625860828423\n",
      "NDCG at 10 Score:  0.48901272587802064\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "unsupervised_model = fasttext.train_unsupervised('amazon_google_raw.txt', model='cbow',dim=300)\n",
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Raw',unsupervised_model,pre_train_model)\n",
    "print(\"Raw\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon vs Google (Cleaned No Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nspace\n",
      "Hit Rate at 10:  0.72895467160037\n",
      "Mean Reciprocal Rank:  0.5584669544660291\n",
      "NDCG at 10 Score:  0.5995544990105128\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "unsupervised_model = fasttext.train_unsupervised('amazon_google_nspace.txt', model='cbow',dim=300)\n",
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Nspace',unsupervised_model,pre_train_model)\n",
    "print(\"Nspace\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon vs Google (Cleaned With Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wspace\n",
      "Hit Rate at 10:  0.6059204440333025\n",
      "Mean Reciprocal Rank:  0.4615086706899841\n",
      "NDCG at 10 Score:  0.49629604388391363\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "unsupervised_model = fasttext.train_unsupervised('amazon_google_wspace.txt', model='cbow',dim=300)\n",
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Wspace',unsupervised_model,pre_train_model)\n",
    "print(\"Wspace\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Using the Pre-Trained + Unsupervised (SkipGram) Average Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Average Cosine Similarity    | Hits Rate at 10 | Mean Reciprocal Rank | NDCG Score at 10 |\n",
    "| ------------------------     | ---   | ---     |   --- |\n",
    "| Abt_buy (Raw)                         | 0.804 |  0.607  | 0.654 |\n",
    "| Abt_buy (Cleaned No Space)            | 0.836 |  0.641  | 0.688 |\n",
    "| Abt_buy (Cleaned With Space)          | 0.738 |  0.533  | 0.581 |\n",
    "| Amazon_Google (Raw)                   | 0.592 |  0.456  | 0.489 |\n",
    "| Amazon_Google (Cleaned No Space)      | 0.729 |  0.558  | 0.600 |\n",
    "| Amazon_Google (Cleaned With Space)    | 0.606 |  0.462  | 0.496 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
