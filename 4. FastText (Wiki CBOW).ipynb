{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "import fasttext\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Facebook FastText Pre-trained Model\n",
    "model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Definitions\n",
    "#### Preprocesing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    # Read in CSV File into DataFrame\n",
    "    list_var = []\n",
    "    data = pd.DataFrame()\n",
    "    with open(filename,'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for i in reader:\n",
    "            list_var.append(i)\n",
    "    # Header & Data\n",
    "    col_name = list_var[0]\n",
    "    data_val = list_var[1:]\n",
    "    # Convert to DataFrame\n",
    "    data = pd.DataFrame(data_val, columns=col_name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data,clean):\n",
    "    # Clean and Tokenize both Name and Description Field\n",
    "    temp_name = data['name'].copy()\n",
    "    temp_description = data['description'].copy()\n",
    "    df = data.copy()\n",
    "    # Raw\n",
    "    if clean=='Raw':\n",
    "        pass\n",
    "    # Semi-Cleaned \n",
    "    elif clean=='Nspace':\n",
    "        # Remove Symbols in Name and Description Column (no space)\n",
    "        temp_name = [re.sub(r'[^\\w\\s]','',x) for x in temp_name]\n",
    "        temp_description = [re.sub(r'[^\\w\\s]','',x) for x in temp_description]\n",
    "    elif clean=='Wspace':\n",
    "        # Remove Symbols in Name and Description Column (replace with space)\n",
    "        temp_name = [re.sub(r'[^\\w\\s]',' ',x) for x in temp_name]\n",
    "        temp_description = [re.sub(r'[^\\w\\s]',' ',x) for x in temp_description]\n",
    "    # Tokenize: Split single sentence into list of words\n",
    "    for i in range(0,len(temp_name),1):\n",
    "        # Tokenize Name and Description Columns into words\n",
    "        df['name'][i] = word_tokenize(temp_name[i])\n",
    "        df['description'][i] = word_tokenize(temp_description[i])\n",
    "        try:\n",
    "            df['name'][i].remove('')\n",
    "        except ValueError:\n",
    "            pass  # do nothing!\n",
    "        try:\n",
    "            df['description'][i].remove('')\n",
    "        except ValueError:\n",
    "            pass  # do nothing!\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df):\n",
    "    # Vectorize the list of words and then average the vectors into one sentence vector\n",
    "    df_vectorize = df.copy()\n",
    "    counter = 0\n",
    "    for i in df['name']:\n",
    "        array = [model.get_word_vector(x) for x in i]\n",
    "        avg = np.average(array, axis=0)\n",
    "        df_vectorize['name'][counter] = avg\n",
    "        counter += 1\n",
    "    df_concat = pd.concat([df.id,df_vectorize.name],axis=1)\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_vector(file,clean):\n",
    "    # Read in Abt File\n",
    "    df = read_file(file)\n",
    "    if 'title' in df.columns:\n",
    "        df['name']=df['title'].copy()\n",
    "    # Clean & Tokenize\n",
    "    temp = tokenize(df,clean)\n",
    "    df.name = temp.name\n",
    "    # Vectorize name column\n",
    "    data = vectorize(df)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Ranked List Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_length(a):\n",
    "    return float(math.sqrt(sum(x*x for x in a)))\n",
    "def dot_product(a,b):\n",
    "    if len(a) == len(b):\n",
    "        return sum([x*y for (x,y) in zip(a,b)])\n",
    "    else:\n",
    "        return \"Vector Length Different\"\n",
    "def cos_similarity(a,b):\n",
    "    return dot_product(a,b)/(vector_length(a)*vector_length(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_ranking(df1,df2):\n",
    "    # Initialize Ranking Chart\n",
    "    col_names = ['df1_id','1','2','3','4','5','6','7','8','9','10']\n",
    "    df_ranking = pd.DataFrame(columns=col_names);\n",
    "    # Loop for every Abt_id element\n",
    "    for i in range(0,len(df1.name),1):\n",
    "        cos_sim = []\n",
    "        # Loop for computing buy_id ranking for current Abt_id\n",
    "        for j in range(0,len(df2.name),1):\n",
    "            # Compute Cosine Similarity for every buy_id element compared to current Abt_id\n",
    "            cos_sim.append(cos_similarity(df1.name[i],df2.name[j]))\n",
    "        # Sort list and pick top 10\n",
    "        temp_df = pd.DataFrame(cos_sim)\n",
    "        temp_sorted = temp_df.sort_values(by=0,ascending=False)\n",
    "        row_ranking = temp_sorted.index.values[0:10]\n",
    "        rank_buy_id = []\n",
    "        # Convert row # into buy_id\n",
    "        for k in row_ranking:\n",
    "            rank_buy_id.append(df2.id.iloc[k])\n",
    "        rank_buy_id.insert(0,df1.id[i])\n",
    "        # Concat into Abt Ranking Chart\n",
    "        combine_df = pd.DataFrame([rank_buy_id],columns=col_names)\n",
    "        df_ranking = pd.concat([df_ranking,combine_df],names=col_names,sort=False,ignore_index=True)\n",
    "    return df_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_ranking_loc(df_ranking,mapping,col1,col2):\n",
    "    # Find where ground truth is ranked \n",
    "    col_names = ['df1_id','Ranked_Location']\n",
    "    df_rank_loc = pd.DataFrame(columns=col_names)\n",
    "    # Loop for every element of Abt_id from df_ranking\n",
    "    for i in range(0,len(df_ranking.df1_id),1):\n",
    "        # Look for ground truth from True Mapping\n",
    "        look_up_id = df_ranking.df1_id[i]\n",
    "        # Check if product is in Perfect Mapping\n",
    "        if len(mapping[col2][mapping[col1]==look_up_id])!=0:\n",
    "            mapped_id = mapping[col2][mapping[col1]==look_up_id].values[0]\n",
    "            # Check if ground truth in ranking list and note its location\n",
    "            if mapped_id in list(df_ranking.iloc[i]):\n",
    "                ranking = list(df_ranking.iloc[i]).index(mapped_id)\n",
    "            else:\n",
    "                ranking = 0\n",
    "            # Concat into Abt Ranking Location df\n",
    "            temp_list = list([look_up_id,ranking])\n",
    "            temp_df2 = pd.DataFrame([temp_list],columns=col_names)\n",
    "            df_rank_loc = pd.concat([df_rank_loc,temp_df2],names=col_names,sort=False,ignore_index=True)\n",
    "    return df_rank_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_at_n(df_rank_loc,n):\n",
    "    # Sum the correct ranks at ranks 1 to n divide by n number of ranks\n",
    "    HR_n_sum = 0\n",
    "    for i in range(0,len(df_rank_loc),1):\n",
    "        if df_rank_loc.Ranked_Location[i]!=0:\n",
    "            if df_rank_loc.Ranked_Location[i]<=n:\n",
    "                HR_n_sum += 1\n",
    "    Hits_Rate_at_n = HR_n_sum/len(df_rank_loc)\n",
    "    return Hits_Rate_at_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(df_rank_loc):\n",
    "    # Sum the Reciprocal Rank of Abt Ranking Location df and divide by total number element\n",
    "    MRR_sum = 0\n",
    "    for i in range(0,len(df_rank_loc),1):\n",
    "        if df_rank_loc.Ranked_Location[i]!=0:\n",
    "            MRR_sum += 1/df_rank_loc.Ranked_Location[i]\n",
    "    mean_reciprocal_rank = MRR_sum/len(df_rank_loc)\n",
    "    return mean_reciprocal_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://gist.github.com/bwhite/3726239\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not idcg:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / idcg\n",
    "\n",
    "def ndcg(df_rank_loc,k):\n",
    "    # Sum up all NDCG at each Queries and divided by total # of Queries\n",
    "    # Initalize Ranking Encoding\n",
    "    rank_encoding = {0:[0,0,0,0,0,0,0,0,0,0],\n",
    "                     1:[1,0,0,0,0,0,0,0,0,0],\n",
    "                     2:[0,1,0,0,0,0,0,0,0,0],\n",
    "                     3:[0,0,1,0,0,0,0,0,0,0],\n",
    "                     4:[0,0,0,1,0,0,0,0,0,0],\n",
    "                     5:[0,0,0,0,1,0,0,0,0,0],\n",
    "                     6:[0,0,0,0,0,1,0,0,0,0],\n",
    "                     7:[0,0,0,0,0,0,1,0,0,0],\n",
    "                     8:[0,0,0,0,0,0,0,1,0,0],\n",
    "                     9:[0,0,0,0,0,0,0,0,1,0],\n",
    "                     10:[0,0,0,0,0,0,0,0,0,1]}\n",
    "    sum_NDCG = 0\n",
    "    for i in df_rank_loc.Ranked_Location:\n",
    "        sum_NDCG += ndcg_at_k(rank_encoding[i], k)\n",
    "    NDCG = sum_NDCG/len(df_rank_loc)\n",
    "    return NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All in One Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_one(file1,file2,mapping,clean):\n",
    "    # Read File 1 & Vectorize\n",
    "    data1 = file_to_vector(file1,clean)\n",
    "    # Read File 2 & Vectorize\n",
    "    data2 = file_to_vector(file2,clean)\n",
    "    # Read Perfect Mapping\n",
    "    mapping = read_file(mapping)\n",
    "    # Create Ranking List\n",
    "    df_ranking = top_10_ranking(data1,data2)\n",
    "    # Find Location where True Ranking Occured \n",
    "    df_rank_loc = true_ranking_loc(df_ranking,mapping,mapping.columns[0],mapping.columns[1])\n",
    "    return df_rank_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abt vs Buy (Raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      "Hit Rate at 10:  0.5550416281221091\n",
      "Mean Reciprocal Rank:  0.3741523868258368\n",
      "NDCG at 10 Score:  0.4168313769100672\n"
     ]
    }
   ],
   "source": [
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Raw')\n",
    "print(\"Raw\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abt vs Buy (Cleaned No Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Space\n",
      "Hit Rate at 10:  0.6540240518038853\n",
      "Mean Reciprocal Rank:  0.47013494266038197\n",
      "NDCG at 10 Score:  0.5136935885442538\n"
     ]
    }
   ],
   "source": [
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Nspace')\n",
    "print(\"No Space\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abt vs Buy (Cleaned With Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Space\n",
      "Hit Rate at 10:  0.5411655874190564\n",
      "Mean Reciprocal Rank:  0.37096126455515854\n",
      "NDCG at 10 Score:  0.41145888784242196\n"
     ]
    }
   ],
   "source": [
    "df_rank_loc = all_in_one('Abt.csv','Buy.csv','abt_buy_perfectMapping.csv','Wspace')\n",
    "print(\"With Space\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon vs Google (Raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      "Hit Rate at 10:  0.43755615453728663\n",
      "Mean Reciprocal Rank:  0.32753248049744\n",
      "NDCG at 10 Score:  0.35343548576432254\n"
     ]
    }
   ],
   "source": [
    "df_rank_loc = all_in_one('Amazon.csv','GoogleProducts.csv','Amzon_GoogleProducts_perfectMapping.csv','Raw')\n",
    "print(\"Raw\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon vs Google (Cleaned No Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Space\n",
      "Hit Rate at 10:  0.5696316262353999\n",
      "Mean Reciprocal Rank:  0.42598689370926546\n",
      "NDCG at 10 Score:  0.46064076567524664\n"
     ]
    }
   ],
   "source": [
    "df_rank_loc = all_in_one('Amazon.csv','GoogleProducts.csv','Amzon_GoogleProducts_perfectMapping.csv','Nspace')\n",
    "print(\"No Space\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon vs Google (Cleaned With Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Space\n",
      "Hit Rate at 10:  0.5426774483378257\n",
      "Mean Reciprocal Rank:  0.40922360558479126\n",
      "NDCG at 10 Score:  0.4413201217866638\n"
     ]
    }
   ],
   "source": [
    "df_rank_loc = all_in_one('Amazon.csv','GoogleProducts.csv','Amzon_GoogleProducts_perfectMapping.csv','Wspace')\n",
    "print(\"With Space\")\n",
    "print(\"Hit Rate at 10: \", hits_at_n(df_rank_loc,10))\n",
    "print(\"Mean Reciprocal Rank: \", mean_reciprocal_rank(df_rank_loc))\n",
    "print('NDCG at 10 Score: ', ndcg(df_rank_loc,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Using the Pre-Trained FastText Model (Wikipedia, CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Pre-Trained (Wiki CBOW)    | Hits Rate at 10 | Mean Reciprocal Rank | NDCG Score at 10 |\n",
    "| ------------------------     | ---   | ---     |   --- |\n",
    "| Abt_buy (Raw)                         | 0.555 |  0.374  | 0.417 |\n",
    "| Abt_buy (Cleaned No Space)            | 0.654 |  0.470  | 0.514 |\n",
    "| Abt_buy (Cleaned With Space)          | 0.541 |  0.371  | 0.411 |\n",
    "| Amazon_Google (Raw)                   | 0.438 |  0.328  | 0.353 |\n",
    "| Amazon_Google (Cleaned No Space)      | 0.570 |  0.426  | 0.461 |\n",
    "| Amazon_Google (Cleaned With Space)    | 0.543 |  0.409  | 0.441 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw + Semi-Cleaned (-,/ Removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   *                  | Hits Rate at 5 | Hits Rate at 10 | Mean Reciprocal Rank | NDCG Score at 10 |\n",
    "| --------------       | ---      | --- | --- | ---|\n",
    "| Abt_buy (Raw)           | 0.494 | 0.578 |  0.384  | 0.430 |\n",
    "| Abt_buy (Cleaned)       | 0.620 | 0.702 |  0.501  | 0.549 |\n",
    "| Amazon_Google (Raw)     | 0.504 | 0.554 |  0.433  | 0.462 |\n",
    "| Amazon_Google (Cleaned) | 0.541  | 0.590 |  0.455 | 0.487 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
